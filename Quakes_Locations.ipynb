{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6abe7c-f1e2-4543-bcb6-44f2390d3174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cartopy in /opt/conda/lib/python3.9/site-packages (0.20.3)\n",
      "Requirement already satisfied: matplotlib>=3.1 in /opt/conda/lib/python3.9/site-packages (from cartopy) (3.5.2)\n",
      "Requirement already satisfied: pyshp>=2.1 in /opt/conda/lib/python3.9/site-packages (from cartopy) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.18 in /opt/conda/lib/python3.9/site-packages (from cartopy) (1.23.1)\n",
      "Requirement already satisfied: pyproj>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from cartopy) (3.3.1)\n",
      "Requirement already satisfied: shapely>=1.6.4 in /opt/conda/lib/python3.9/site-packages (from cartopy) (1.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.1->cartopy) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.1->cartopy) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.1->cartopy) (20.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.1->cartopy) (4.34.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.1->cartopy) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.1->cartopy) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.1->cartopy) (0.11.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from pyproj>=3.0.0->cartopy) (2022.6.15)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.1->cartopy) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install obspy\n",
    "import sys\n",
    "!{sys.executable} -m pip install cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b31e04d-8d2b-4211-a688-1373f12d1e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement mpl_toolkits (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for mpl_toolkits\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install mpl_toolkits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb68338b-3ad3-44c8-ac32-a1a1703a1c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this first\n",
    "import obspy\n",
    "import numpy as np\n",
    "from obspy.clients.fdsn.client import Client\n",
    " ##TODOli Can't install cartopy on Noah's local machine\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.pyplot import figure, show, rc\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs                   # import projections\n",
    "import cartopy.feature as cf \n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "# import Basemap\n",
    "# from mpl_toolkits.basemap import Basemap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e79ad9-6191-4ca3-8b87-6916fba0b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell to define functions\n",
    "\n",
    "def quakeML_Loader(filepath): #Loads quakeML file formats as Catalog\n",
    "    # Make an obspy Catalog object from the QuakeML file.\n",
    "    return obspy.core.event.read_events(filepath)\n",
    "    #Copied from Maleen's code\n",
    "    #Not sure this 1-line function actually needs to exist\n",
    "\n",
    "def generate_summary(cat): #function that generates a summary table of data from a catalog of events for identification of best candidate events\n",
    "    resource_ids = []\n",
    "    magnitudes = []\n",
    "    pick_counts =[]\n",
    "    epi_lats = []\n",
    "    epi_longs = []\n",
    "    times = []\n",
    "    depths = []\n",
    "    for event in cat:\n",
    "        resource_ids.append(event.resource_id)\n",
    "        magnitudes.append(event.magnitudes[0].mag)\n",
    "        pick_counts.append(len(event.picks))\n",
    "        epi_lats.append(event.origins[0].latitude)\n",
    "        epi_longs.append(event.origins[0].longitude)\n",
    "        times.append(event.origins[0].time)\n",
    "        depths.append(event.origins[0].depth)\n",
    "    summary = pd.DataFrame(resource_ids, magnitudes).reset_index()\n",
    "    summary.columns = ['magnitudes','resource_ids']\n",
    "    summary['pick_counts'] = pick_counts #unsure why this needs to be done on its own but it works\n",
    "    summary['epi_lats'] = epi_lats\n",
    "    summary['epi_longs'] = epi_longs\n",
    "    summary['times'] = times\n",
    "    summary['depths'] = depths\n",
    "    #these two lines can be edited for legibility and helpfulness\n",
    "    print('Biggest earthquake was', summary.sort_values(by='magnitudes', ascending = False).get('resource_ids').iloc[0],'with magnitude',str(summary.sort_values(by='magnitudes', ascending = False).get('magnitudes').iloc[0])+'.')\n",
    "    print('Best picked earthquake was', summary.sort_values(by='pick_counts', ascending = False).get('resource_ids').iloc[0],'with',summary.sort_values(by='pick_counts', ascending = False).get('pick_counts').iloc[0],'picks.')\n",
    "    #TODO get index position(s) of most relevant quakes, but for our data set it's i = 170\n",
    "    return summary\n",
    "\n",
    "def quakeML_Reader(event):\n",
    "    epicenter = (event.origins[0].latitude, event.origins[0].longitude) #stores event epicenter lat/lon as tuple\n",
    "    magnitude = event.magnitudes[0].mag #stores event magnitude\n",
    "    birthday = event.origins[0].time #stores time at which event occurs\n",
    "    results = []\n",
    "    for arrival in event.origins[0].arrivals: #goes through arrival data and notes phase, azimuthal angle, distance from epicenter and pick_id in 2D list\n",
    "        phase = arrival.phase\n",
    "        azi = arrival.azimuth\n",
    "        dist = arrival.distance * 111 #there is a note in Maleen's code about this being in degrees\n",
    "        pick_id = arrival.pick_id\n",
    "        result = [phase, azi, dist, pick_id]\n",
    "        results.append(result)\n",
    "    arrivals = pd.DataFrame(results)\n",
    "    arrivals.columns = ['phase','azimuth','distance','pick_id'] #makes DataFrame of arrivals data\n",
    "    results = []\n",
    "    for pick in event.picks: #goes through pick data and notes time of arrival, station data and pick_id in 2D list\n",
    "        pick_id = pick.resource_id\n",
    "        time = pick.time\n",
    "        network_code = pick.waveform_id.network_code\n",
    "        station_code = pick.waveform_id.station_code\n",
    "        channel_code =pick.waveform_id.channel_code\n",
    "        result = [pick_id, time, network_code, station_code, channel_code]\n",
    "        results.append(result)\n",
    "    picks = pd.DataFrame(results)\n",
    "    picks.columns = ['pick_id','time','network_code','station_code','channel_code'] #makes DataFrame of picks data\n",
    "    picks['travel_time'] = picks['time'] - birthday\n",
    "    log = arrivals.merge(picks, left_on='pick_id', right_on='pick_id').sort_values(by='travel_time') #merges arrivals and picks data\n",
    "    log['velocity'] = log['distance'] / log['travel_time']\n",
    "    bonus = (epicenter, magnitude, birthday) #TODO integrate bonus\n",
    "\n",
    "    #adds lat lon to picks\n",
    "    #code borrowed from Zoe's explore_data.ipynb\n",
    "    sta_list = np.unique(log.station_code)\n",
    "\n",
    "    # Get all the info for those stations from IRIS\n",
    "    network = \",\".join((np.unique(log.network_code)).tolist())\n",
    "    channel = \",\".join((np.unique(log.channel_code)).tolist())\n",
    "    station = \",\".join((np.unique(log.station_code)).tolist())\n",
    "\n",
    "    starttime = np.min(log['time'])\n",
    "    endtime = np.max(log['time'])\n",
    "\n",
    "    sta_metadata = Client(\"iris\").get_stations(starttime=starttime,endtime=endtime,network=network,channel=channel,station=station,location='',level='response')\n",
    "\n",
    "    station_locs = defaultdict(dict)\n",
    "    for network in sta_metadata:\n",
    "        for station in network:\n",
    "            for chn in station:\n",
    "                sid = f\"{network.code}.{station.code}.{chn.location_code}.{chn.code[:-1]}\" + chn.start_date.strftime('%Y%j')\n",
    "                if sid in station_locs:\n",
    "                    station_locs[sid][\"component\"] += f\",{chn.code[-1]}\"\n",
    "                    station_locs[sid][\"response\"] += f\",{chn.response.instrument_sensitivity.value:.2f}\"\n",
    "                else:\n",
    "                    component = f\"{chn.code[-1]}\"\n",
    "                    response = f\"{chn.response.instrument_sensitivity.value:.2f}\"\n",
    "                    dtype = chn.response.instrument_sensitivity.input_units.lower()\n",
    "                    tmp_dict = {}\n",
    "                    tmp_dict[\"longitude\"], tmp_dict[\"latitude\"], tmp_dict[\"elevation(m)\"] = (\n",
    "                        chn.longitude,\n",
    "                        chn.latitude,\n",
    "                        chn.elevation,\n",
    "                    )\n",
    "                    tmp_dict[\"component\"], tmp_dict[\"response\"], tmp_dict[\"unit\"] = component, response, dtype\n",
    "                    tmp_dict[\"start_date\"], tmp_dict[\"end_date\"] = chn.start_date,chn.end_date\n",
    "                    tmp_dict[\"network\"], tmp_dict[\"station\"] = network.code, station.code\n",
    "                    station_locs[sid] = tmp_dict\n",
    "\n",
    "    station_locs = pd.DataFrame.from_dict(station_locs,orient='index')\n",
    "    station_locs[\"id\"] = station_locs.index\n",
    "    # Remove the date from ID\n",
    "    station_locs['id']=station_locs['id'].str.slice(stop=-7)\n",
    "    loc_log = log.merge(station_locs, left_on='station_code',right_on='station').drop(columns=['component','response','unit','start_date','end_date','id','network_code','station_code'])\n",
    "    return loc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7bdc52-f9a4-4525-abc8-912e6c1011a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = quakeML_Loader('XO_2019_01.quakeml') #loads quakeML file as events Catalog\n",
    "\n",
    "#Should take about 1 minute to run on Noah's laptop, be patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b6e73-0a37-4e20-bc08-11900228d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_summary(cat) #summarizes events and identifies most relevant\n",
    "# generate_summary(cat)\n",
    "df = generate_summary(cat)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a416fdc-393a-448c-9fe5-5815e7f38717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['year'] = pd.DatetimeIndex(df['times']).year # add year as a category to group by\n",
    "df['marker_size'] =np.fix(np.exp(df['magnitudes'])) # add marker size as exp(mag)\n",
    "df['magnitude bin'] = 0.5*np.fix(2*df['magnitudes']) # add marker size as exp(mag)\n",
    "df['location'] = 'Alaskan Coast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac06ad-db74-4d47-a911-2b101bb50aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of earthquakes\n",
    "fig = px.scatter_geo(df,\n",
    "                     lat='epi_lats',lon='epi_longs', \n",
    "                     size='marker_size', color='magnitudes',\n",
    "                     hover_name='location', \n",
    "                     hover_data=['magnitudes','depths'],\n",
    "                     scope='north america',\n",
    "                     range_color=(min(df['magnitudes']),max(df['magnitudes'])),\n",
    "                     height=600, width=1000,\n",
    "                     #animation_frame=\"year\"\n",
    "                    );\n",
    "\n",
    "# focus point\n",
    "# lat_foc = 55\n",
    "# lon_foc = -165\n",
    "lat_foc = 63\n",
    "lon_foc = -175\n",
    "fig.update_layout(\n",
    "        geo = dict(\n",
    "            projection_scale=3, #this is kind of like zoom\n",
    "            center=dict(lat=lat_foc, lon=lon_foc), # this will center on the point\n",
    "        ))\n",
    "\n",
    "fig.update_geos(resolution=50, showcountries=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3222491f-ab89-481a-a4b2-5a4755b8b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = cat[170] #biggest and most documented quake\n",
    "log = quakeML_Reader(event) #be patient, this should take like 10s\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85e9df-6070-4a0e-9030-679a99719f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(log,\n",
    "                     lat='latitude',lon='longitude', \n",
    "                     # size='marker_size', color='magnitudes',\n",
    "                     hover_name='station', \n",
    "                     hover_data=['distance','velocity', 'travel_time'],\n",
    "                     scope='north america',\n",
    "                     # range_color=(min(df['magnitudes']),max(df['magnitudes'])),\n",
    "                     height=600, width=1000,\n",
    "                     #animation_frame=\"year\"\n",
    "                    );\n",
    "\n",
    "# focus point\n",
    "# lat_foc = 55\n",
    "# lon_foc = -165\n",
    "lat_foc = 63\n",
    "lon_foc = -175\n",
    "fig.update_layout(\n",
    "        geo = dict(\n",
    "            projection_scale=3, #this is kind of like zoom\n",
    "            center=dict(lat=lat_foc, lon=lon_foc), # this will center on the point\n",
    "        ))\n",
    "\n",
    "fig.update_geos(resolution=50, showcountries=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
